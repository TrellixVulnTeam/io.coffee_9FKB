# A passthrough read/write stream that sets its properties
# based on a header, extendedHeader, and globalHeader
#
# Can be either a file system object of some sort, or
# a pax/ustar metadata entry.
Entry = (header, extended, global) ->
  Stream.call this
  @readable = true
  @writable = true
  @_needDrain = false
  @_paused = false
  @_reading = false
  @_ending = false
  @_ended = false
  @_remaining = 0
  @_queue = []
  @_index = 0
  @_queueLen = 0
  @_read = @_read.bind(this)
  @props = {}
  @_header = header
  @_extended = extended or {}
  
  # globals can change throughout the course of
  # a file parse operation.  Freeze it at its current state.
  @_global = {}
  me = this
  Object.keys(global or {}).forEach (g) ->
    me._global[g] = global[g]
    return

  @_setProps()
  return
module.exports = Entry
TarHeader = require("./header.js")
tar = require("../tar")
assert = require("assert").ok
Stream = require("stream").Stream
inherits = require("inherits")
fstream = require("fstream").Abstract
inherits Entry, Stream
Entry::write = (c) ->
  @error "write() after end()", null, true  if @_ending
  @error "invalid bytes past eof"  if @_remaining is 0
  
  # often we'll get a bunch of \0 at the end of the last write,
  # since chunks will always be 512 bytes when reading a tarball.
  c = c.slice(0, @_remaining)  if c.length > @_remaining
  @_remaining -= c.length
  
  # put it on the stack.
  ql = @_queueLen
  @_queue.push c
  @_queueLen++
  @_read()
  
  # either paused, or buffered
  if @_paused or ql > 0
    @_needDrain = true
    return false
  true

Entry::end = (c) ->
  @write c  if c
  @_ending = true
  @_read()
  return

Entry::pause = ->
  @_paused = true
  @emit "pause"
  return

Entry::resume = ->
  
  # console.error("    Tar Entry resume", this.path)
  @emit "resume"
  @_paused = false
  @_read()
  @_queueLen - @_index > 1


# This is bound to the instance
Entry::_read = ->
  
  # console.error("    Tar Entry _read", this.path)
  
  # set this flag so that event handlers don't inadvertently
  # get multiple _read() calls running.
  return @_reading = true  if @_paused or @_reading or @_ended
  
  # have any data to emit?
  while @_index < @_queueLen and not @_paused
    chunk = @_queue[@_index++]
    @emit "data", chunk
  
  # check if we're drained
  if @_index >= @_queueLen
    @_queue.length = @_queueLen = @_index = 0
    if @_needDrain
      @_needDrain = false
      @emit "drain"
    if @_ending
      @_ended = true
      @emit "end"
  
  # if the queue gets too big, then pluck off whatever we can.
  # this should be fairly rare.
  mql = @_maxQueueLen
  if @_queueLen > mql and @_index > 0
    mql = Math.min(@_index, mql)
    @_index -= mql
    @_queueLen -= mql
    @_queue = @_queue.slice(mql)
  @_reading = false
  return

Entry::_setProps = ->
  
  # props = extended->global->header->{}
  header = @_header
  extended = @_extended
  global = @_global
  props = @props
  
  # first get the values from the normal header.
  fields = tar.fields
  f = 0

  while fields[f] isnt null
    field = fields[f]
    val = header[field]
    props[field] = val  if typeof val isnt "undefined"
    f++
  
  # next, the global header for this file.
  # numeric values, etc, will have already been parsed.
  [
    global
    extended
  ].forEach (p) ->
    Object.keys(p).forEach (f) ->
      props[f] = p[f]  if typeof p[f] isnt "undefined"
      return

    return

  
  # no nulls allowed in path or linkpath
  [
    "path"
    "linkpath"
  ].forEach (p) ->
    props[p] = props[p].split("\u0000")[0]  if props.hasOwnProperty(p)
    return

  
  # set date fields to be a proper date
  [
    "mtime"
    "ctime"
    "atime"
  ].forEach (p) ->
    props[p] = new Date(props[p] * 1000)  if props.hasOwnProperty(p)
    return

  
  # set the type so that we know what kind of file to create
  type = undefined
  switch tar.types[props.type]
    when "OldFile", "ContiguousFile"
      type = "File"
    when "GNUDumpDir"
      type = "Directory"
    when `undefined`
      type = "Unknown"
    when "Link", "SymbolicLink", "CharacterDevice", "BlockDevice", "Directory", "FIFO"
    else
      type = tar.types[props.type]
  @type = type
  @path = props.path
  @size = props.size
  
  # size is special, since it signals when the file needs to end.
  @_remaining = props.size
  return

Entry::warn = fstream.warn
Entry::error = fstream.error
